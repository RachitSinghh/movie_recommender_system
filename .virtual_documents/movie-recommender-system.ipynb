import numpy as np
import pandas as pd


movies  = pd.read_csv('tmdb_5000_movies.csv')
credits = pd.read_csv('tmdb_5000_credits.csv')


movies = movies.merge(credits, on='title')


movies.head(1)


# Genres 
# id 
# keywords
# title
# overview
# cast
# crew
movies = movies[['id', 'title','overview','genres','keywords','cast','crew']]


movies.info()


movies.head()





movies.isnull().sum()


movies.dropna(inplace=True)


movies.duplicated().sum()


movies.iloc[0].genres


# ['Action','Adventure','FFantasy','Scifi']


import ast
def convert(obj):
    l = []
    for i in ast.literal_eval(obj):
        l.append(i['name'])
    return l


movies['genres'] = movies['genres'].apply(convert)


movies.head()


movies['keywords'] = movies['keywords'].apply(convert)


def convert(obj):
    l = []
    count = 0
    for i in ast.literal_eval(obj):
        if count != 3:
            l.append(i['name'])
            count += 1
        else:
            break
    return l


movies['cast'] = movies['cast'].apply(convert)


movies['crew'][0]


def fetch_director(obj):
    l = []
    for i in ast.literal_eval(obj):
        if i['job'] == 'Director':
            l.append(i['name'])
            break
    return l


movies['crew'] = movies['crew'].apply(fetch_director)


movies.head()


movies['overview'] = movies['overview'].apply(lambda x:x.split())
# movies.sample(5)


movies['genres'] = movies['genres'].apply(lambda x:[i.replace(" ","")for i in x])
movies['keywords'] = movies['keywords'].apply(lambda x:[i.replace(" ","")for i in x])
movies['cast'] = movies['cast'].apply(lambda x:[i.replace(" ","")for i in x])
movies['crew'] = movies['crew'].apply(lambda x:[i.replace(" ","")for i in x])


movies.head()


movies['tags'] = movies['overview'] + movies['genres'] + movies['keywords'] + movies['cast'] + movies['crew']


movies.head()


new_df = movies[['id','title','tags']]


new_df


new_df['tags'].apply(lambda x:" ".join(x))


new_df['tags'] = new_df['tags'].apply(lambda x:" ".join(x))


new_df.head()


new_df['tags'][0]


import nltk


from nltk.stem.porter import PorterStemmer
ps = PorterStemmer()


def stem(text):
    y = []

    for i in text.split():
        y.append(ps.stem(i))
    
    return " ".join(y)



new_df['tags'] = new_df['tags'].apply(stem)


new_df['tags'] = new_df['tags'].apply(lambda x:x.lower())


new_df.head()


new_df['tags'][1]


from sklearn.feature_extraction.text import CountVectorizer
cv = CountVectorizer(max_features=5000, stop_words='english')


vectors = cv.fit_transform(new_df['tags']).toarray()


vectors


print(cv.get_feature_names_out())


ps.stem('loving')


stem("captain barbossa, long believed to be dead, has come back to life and is headed to the edge of the earth with will turner and elizabeth swann. but nothing is quite as it seems. adventure fantasy action ocean drugabuse exoticisland eastindiatradingcompany loveofone'slife traitor shipwreck strongwoman ship alliance calypso afterlife fighter pirate swashbuckler aftercreditsstinger johnnydepp orlandobloom keiraknightley goreverbinski"
)
